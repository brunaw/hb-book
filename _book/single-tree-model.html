<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Single tree model | Mixed BART Models: maths and discussion</title>
  <meta name="description" content="Chapter 2 Single tree model | Mixed BART Models: maths and discussion" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Single tree model | Mixed BART Models: maths and discussion" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Single tree model | Mixed BART Models: maths and discussion" />
  
  
  

<meta name="author" content="Bruna Wundervald" />


<meta name="date" content="2022-08-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="initial-results.html"/>
<script src="libs/header-attrs-2.14/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mixed BART book</a></li>

<li class="divider"></li>
<li><a href="index.html#intro" id="toc-intro"><span class="toc-section-number">1</span> Intro<span></span></a></li>
<li><a href="single-tree-model.html#single-tree-model" id="toc-single-tree-model"><span class="toc-section-number">2</span> Single tree model<span></span></a>
<ul>
<li><a href="single-tree-model.html#model-specification" id="toc-model-specification"><span class="toc-section-number">2.1</span> Model specification<span></span></a></li>
<li><a href="single-tree-model.html#maths" id="toc-maths"><span class="toc-section-number">2.2</span> Maths<span></span></a></li>
<li><a href="single-tree-model.html#posteriors" id="toc-posteriors"><span class="toc-section-number">2.3</span> Posteriors<span></span></a></li>
<li><a href="single-tree-model.html#posterior-for-tau" id="toc-posterior-for-tau"><span class="toc-section-number">2.4</span> Posterior for <span class="math inline">\(\tau\)</span><span></span></a></li>
<li><a href="single-tree-model.html#posterior-for-mu_jp" id="toc-posterior-for-mu_jp"><span class="toc-section-number">2.5</span> Posterior for <span class="math inline">\(\mu_j,p\)</span><span></span></a></li>
<li><a href="single-tree-model.html#posterior-for-mu" id="toc-posterior-for-mu"><span class="toc-section-number">2.6</span> Posterior for <span class="math inline">\(\mu\)</span><span></span></a></li>
<li><a href="single-tree-model.html#a-second-posterior-with-mu_j-marginalised-out" id="toc-a-second-posterior-with-mu_j-marginalised-out"><span class="toc-section-number">2.7</span> A second posterior, with <span class="math inline">\(\mu_j\)</span> marginalised out<span></span></a></li>
<li><a href="single-tree-model.html#marginal-distributions-for-y" id="toc-marginal-distributions-for-y"><span class="toc-section-number">2.8</span> Marginal Distributions for y<span></span></a>
<ul>
<li><a href="single-tree-model.html#log-version-of-the-marginal" id="toc-log-version-of-the-marginal"><span class="toc-section-number">2.8.1</span> log version of the marginal:<span></span></a></li>
<li><a href="single-tree-model.html#old-marginal-distributions" id="toc-old-marginal-distributions"><span class="toc-section-number">2.8.2</span> (Old) Marginal Distributions<span></span></a></li>
</ul></li>
<li><a href="single-tree-model.html#algorithm" id="toc-algorithm"><span class="toc-section-number">2.9</span> Algorithm<span></span></a></li>
</ul></li>
<li><a href="initial-results.html#initial-results" id="toc-initial-results"><span class="toc-section-number">3</span> Initial results<span></span></a></li>
<li><a href="bart.html#bart" id="toc-bart"><span class="toc-section-number">4</span> BART<span></span></a>
<ul>
<li><a href="bart.html#a-bart-version-of-our-hierachical-trees-model" id="toc-a-bart-version-of-our-hierachical-trees-model"><span class="toc-section-number">4.1</span> A BART version of our hierachical trees model<span></span></a></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/brunaw/mixed_bart" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mixed BART Models: maths and discussion</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="single-tree-model" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Single tree model<a href="single-tree-model.html#single-tree-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="model-specification" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Model specification<a href="single-tree-model.html#model-specification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Define the following model. Suppose we have the observation of a tree node as:
<span class="math display">\[y_{ij}, i = 1,\ldots,n_j, \; j = 1\ldots, m\]</span>
where <span class="math inline">\(y_{ij}\)</span> is observation <span class="math inline">\(i\)</span> in group <span class="math inline">\(j\)</span>. There are different numbers of observations <span class="math inline">\(n_j\)</span> in each group, so for example <span class="math inline">\(n_1\)</span> is the number of observations in group 1, etc. There are <span class="math inline">\(m\)</span> groups. The total number of observations is <span class="math inline">\(n = \sum_{j=1}^m n_j\)</span></p>
<p>Then, for each tree node, suppose we have the likelihood:
<span class="math display">\[y_{ij} \sim N(\mu_j, \tau^{-1})\]</span></p>
<p>so each group has an overall mean <span class="math inline">\(\mu_j\)</span>, with an overall precision term <span class="math inline">\(\tau\)</span>.</p>
<p>We then have a hierarchical prior distribution:</p>
<p><span class="math display">\[\mu_j \sim N(\mu, k_1 (\tau^{-1}))\]</span></p>
<p>where <span class="math inline">\(k_1\)</span> will be taken as a constant for simplicity,
and the hyper-parameter prior distributions are:</p>
<p><span class="math display">\[\mu \sim N(0, \tau_{\mu} = k_2 (\tau^{-1}))\]</span>
<span class="math display">\[\tau \sim Ga(\alpha, \beta)\]</span></p>
<p>Where the values <span class="math inline">\(k_1, k_2, \alpha, \beta\)</span> are all fixed.</p>
</div>
<div id="maths" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Maths<a href="single-tree-model.html#maths" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>The likelihood of each tree node will be:</li>
</ul>
<p><span class="math display">\[\begin{equation}
L = \prod_{j = 1}^{m} \prod_{i = 1}^{n_j} p(y_{ij} | \mu_{j}, \tau) \\
L \propto \tau^{n/2} exp \{ -\frac{\tau}{2} \sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \}
\end{equation}\]</span></p>
<p>with prior distributions:</p>
<ul>
<li><span class="math inline">\(\mu_j | \mu, \tau, k_1\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\mu_1, \dots, \mu_m | \mu, \tau) \propto (\tau/k_1)^{m/2}
exp\{ - \frac{\tau}{2k_1} \sum_{j = 1}^{m} (\mu_j - \mu)^2  \}
\end{equation}\]</span></p>
<ul>
<li><span class="math inline">\(\tau | \alpha, \beta\)</span></li>
</ul>
<p><span class="math display">\[p(\tau | \alpha, \beta) \propto \tau^{\alpha - 1} exp\{ - \beta \tau \}\]</span></p>
<ul>
<li><span class="math inline">\(\mu | \tau_{\mu} = k_2 (\tau^{-1})\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\mu | k_2, \tau) \propto (\tau/k_2)^{1/2}
exp\{ - \frac{ \tau}{2 k_2} \mu^2  \}  \}
\end{equation}\]</span></p>
<p>and their joint distribution as:</p>
<ul>
<li><span class="math inline">\(p(\tau, \mu_1, \dots, \mu_m, \mu| y, k_1, k_2, \tau, \alpha, \beta)\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\tau, \mu_1, \dots, \mu_m, \mu| y, k_1, k_2, \tau, \alpha, \beta)
\propto

\tau^{\alpha - 1} exp\{ - \beta \tau \} \times \\

(\tau/k_1)^{m/2}
exp\{ - \frac{\tau}{2k_1} \sum_{j = 1}^{m} (\mu_j - \mu)^2  \} \\
\times  
(\tau/k_2)^{1/2}
exp\{ - \frac{ \tau}{2 k_2} \mu^2  \}
\times \tau^{n/2} exp \{ -\frac{\tau}{2} \sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \}
\end{equation}\]</span></p>

</div>
<div id="posteriors" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Posteriors<a href="single-tree-model.html#posteriors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="posterior-for-tau" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Posterior for <span class="math inline">\(\tau\)</span><a href="single-tree-model.html#posterior-for-tau" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><span class="math inline">\(p(\tau | \mu_1, \dots, \mu_m, y, \alpha, \beta, k_1)\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\tau | \mu_1, \dots, \mu_m, y, \alpha, \beta, k_1) \propto
\tau^{\alpha - 1} exp\{ - \beta \tau \}  \times \\

(\tau/(k_1/P))^{m/2} exp \{ -\frac{\tau}{2(k_1/P)} \sum_{j = 1}^{m}
(\mu_{j} - \mu)^2 \} \times \\

\tau^{n/2} exp \{ -\frac{\tau}{2} \sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \} \times
(\tau/k_2)^{1/2}
exp\{ - \frac{ \tau}{2 k_2} \mu^2  \}  \\

\propto \tau^{(n+m+1)/2  + \alpha - 1 }
exp \{ - \tau \Big( \frac{\sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2}{2} + \beta  +
\frac{\sum_{j = 1}^{m}(\mu_{j} - \mu)^2}{29(k_1/P)} +
\frac{\mu^2}{2k_2}\Big) \}
\end{equation}\]</span></p>
<p>So <span class="math inline">\(\tau | \mu_1, \dots, \mu_m, y, \alpha, \beta, k_1, k_2 \sim \\ \text{Gamma}((n+m+1)/2 + \alpha, \Big( \frac{\sum_{j = 1}^{m} \sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2}{2} + \beta + \frac{\sum_{j = 1}^{m}(\mu_{j} - \mu)^2}{2(k_1/P)} + \frac{\mu^2}{2k_2})\Big)\)</span></p>
</div>
<div id="posterior-for-mu_jp" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Posterior for <span class="math inline">\(\mu_j,p\)</span><a href="single-tree-model.html#posterior-for-mu_jp" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="math display">\[\begin{equation}
Q =    (\tau/(k_1/P)) \sum_{j=1}^{m} (\mu_j - \mu)^2 +
\tau \sum_{j = 1}^{m} \sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \\

Q =    \tau [ \sum_{j = 1}^{m} n_j \mu_j^2 + \frac{\mu_j^2}{(k_1/P)} -  
(\sum_{j = 1}^{m} \frac{2 \mu \mu_j}{(k_1/P)} + 2 \bar y_j n_j \mu_j)] \\

Q \propto    \tau [ \sum_{j = 1}^{m} (n_j + \frac{1}{(k_1/P)}) \mu_j^2 -  
2 \mu_j (\frac{\mu}{(k_1/P)} +  \bar y_j n_j )] \\

Q \propto \tau [ \sum_{j = 1}^{m} (n_j + \frac{1}{(k_1/P)})(\mu_j -  
\frac{\mu/(k_1/P) +  \bar y_j n_j}{n_j + 1/(k_1/P)})^2]\\

\end{equation}\]</span>
So for each <span class="math inline">\(\mu_j\)</span></p>
<p><span class="math display">\[\mu_j | \mu, y, \tau, k_1 \sim N(\frac{\mu/(k_1/P) +  \bar y_j n_j}{n_j + 1/(k_1/P)}, ((n_j + \frac{1}{(k_1/P)}) \tau )^{-1})\]</span></p>
</div>
<div id="posterior-for-mu" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Posterior for <span class="math inline">\(\mu\)</span><a href="single-tree-model.html#posterior-for-mu" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Similarly, for <span class="math inline">\(\mu\)</span> we have:</p>
<p><span class="math display">\[\begin{equation}
Q =   \Big[\frac{\tau}{(k_1/P)} \sum_{j = 1}^{m} (\mu_j - \mu)^2 +  \frac{ \tau}{k_2} \mu^2\Big] \\

Q =     \Big[\frac{\tau}{(k_1/P)}  \sum_{j=1}^{m} (\mu_j^{2} - 2 \mu \mu_j + \mu^2) +
  \frac{ \tau}{k_2} \mu^2 \Big] \\


Q \propto  \Big[(\frac{\tau}{k_2} + \frac{\tau m }{(k_1/P)}) \mu^2 -
\frac{2\tau}{(k_1/P)} \sum_{j=1}^{m} \mu \mu_j \Big]\\

Q \propto \Big[ (\frac{\tau}{k_2} + \frac{\tau m}{(k_1/P)}) \mu^2 -
\frac{2\tau}{(k_1/P)}  \mu \bar \mu m \Big]\\


Q \propto (\tau(\frac{m}{(k_1/P)} + \frac{1}{k_2}))(\mu -
\frac{\bar \mu  m/(k_1/P) }{\tau(\frac{m}{(k_1/P)} + \frac{1}{k_2})})^2
\end{equation}\]</span></p>
<p>So for <span class="math inline">\(\mu\)</span> we have that the conditional distribution:</p>
<p><span class="math display">\[\mu | \mu_1, \dots, \mu_{m}, \mu_{\mu}, k_1, k_2, \tau \sim N(
\frac{\bar \mu m /(k_1/P) }{\tau(\frac{m}{(k_1/P)} + \frac{1}{k_2})},
\tau(\frac{m}{(k_1/P)} + \frac{1}{k_2})^{-1})\]</span></p>
</div>
<div id="a-second-posterior-with-mu_j-marginalised-out" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> A second posterior, with <span class="math inline">\(\mu_j\)</span> marginalised out<a href="single-tree-model.html#a-second-posterior-with-mu_j-marginalised-out" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The following is what is used in the code.</p>
<p>Assuming
<span class="math display">\[ y | \tau, k_1, k_2 \sim N(0, \tau^{-1}[(k_1 \mathbf{M}\mathbf{M}^{T} + \mathbf{I}) + k_2 \mathbf{1}\mathbf{1}^{T}])\]</span></p>
<p>we can do</p>
<p><span class="math display">\[\begin{equation}
p(\mu | y, \alpha, \beta, k_1, k_2) \propto
\exp \{ -\frac{\tau}{2}(\mathbf{y} - \mu \mathbf{1})^{T} \Psi^{-1}
(\mathbf{y} - \mu \mathbf{1}) \} \times \\
\exp \{ -\frac{\tau}{2 k_2} \mu^{2} \} \\

\propto
\exp \{ -\frac{\tau}{2}(\mu^{2} (\mathbf{1}^{T} \Psi^{-1} \mathbf{1}
+ 1/k_2) - 2 \mu \mathbf{1}^{T} \Psi^{-1} \mathbf{y} + \mu^2/k_2) \}
\\

\propto
\exp \{ -\frac{\tau}{2}[(
\mathbf{1}^{T} \Psi^{-1} \mathbf{1}+ 1/k_2)(
\mu^2  -
\frac{2 \mu \mathbf{1}^{T} \Psi^{-1} \mathbf{y}}{\mathbf{1}^{T} \Psi^{-1} \mathbf{1} + 1/k_1}) \}
\\
\end{equation}\]</span></p>
<p><span class="math display">\[\mu | y, \tau, k_1, k_2 \sim MVN(\frac{\mathbf{1}^{T}\Psi^{-1}\mathbf{y}}{\mathbf{1}^{T}\Psi^{-1}\mathbf{1} + k_2^{-1}},
((\mathbf{1}^{T}\Psi^{-1}\mathbf{1} + k_2^{-1}) \tau )^{-1})\]</span></p>

</div>
<div id="marginal-distributions-for-y" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Marginal Distributions for y<a href="single-tree-model.html#marginal-distributions-for-y" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we have the outcome variable:
<span class="math display">\[\mathbf{y} \sim MVN_n(\mu \mathbf{1}_n, \tau^{-1} (k_1 \mathbf{MM}^T + \mathbf{I}))\]</span></p>
<p>with:
<span class="math display">\[\mu \sim N(\mu_\mu, \tau_\mu^{-1})\]</span></p>
<p>And define <span class="math inline">\(\mathbf{\Psi} = k_1 \mathbf{MM}^T + \mathbf{I}\)</span></p>
<p>Then, as a ‘trick’ to estimate the mean and variance of <span class="math inline">\(\mathbf{y}\)</span>, we can write:</p>
<p><span class="math display">\[\mathbf{y} = \mu \mathbf{1}_n + \left[ \tau^{-1} \Psi \right]^{1/2} \mathbf{z}\]</span></p>
<p>where <span class="math inline">\(\mathbf{z} \sim MVN(0, \mathbf{I})\)</span> is a standard multivariate normal. Then we have:</p>
<p><span class="math display">\[E(\mathbf{y}) = \mu_\mu \mathbf{1}_n + 0 = \mu_\mu \mathbf{1}_n \\
Var(\mathbf{y}) = Var(\mu \mathbf{1}_n) +
Var(\left[\tau^{-1} \Psi \right]^{1/2}) = \tau_{\mu}^{-1} \mathbf{1}_n \mathbf{1}^T_n + \tau^{-1} \mathbf{\Psi}\]</span></p>
<p>Now let <span class="math inline">\(\tau_\mu^{-1} = k_2 \tau^{-1}\)</span>, we get:</p>
<p><span class="math display">\[\mathbf{y} \sim MVN(\mu_\mu \mathbf{1}, \tau^{-1} \left[ k_2 \mathbf{1}_n \mathbf{1}^T_n  +  \mathbf{\Psi} \right]) \equiv MVN(W_0, \tau^{-1} W_1)\]</span></p>
<p>We now want to marginalize this over <span class="math inline">\(\tau \sim Ga(\alpha, \beta)\)</span>, by integrating out a Gamma distribution with:</p>
<p><span class="math display">\[ Ga\Big(n/2 + \alpha, \beta + \frac{(\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)}{2}\Big) \]</span></p>
<p>…so we get:</p>
<p><span class="math display">\[\pi(\mathbf{y} | \mu_\mu, k_1, k_2) = \int
(2\pi)^{-n/2}
\tau^{n/2} | \mathbf{W}_1 |^{-1/2} \exp \left[ -\frac{\tau}{2} (\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)\right] \tau^{\alpha - 1} \exp(-\beta \tau) \partial \tau\]</span></p>
<p>This becomes:</p>
<p><span class="math display">\[ = (2\pi)^{-n/2} | \mathbf{W}_1 |^{-1/2} \Gamma \left( \frac{n}{2} + \alpha \right) \left[ \frac{(\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)}{2} + \beta\right]^{-\left(\frac{n}{2} + \alpha \right)}\]</span></p>
<p>(For examples of the evaluation of this marginal
distribution, see )</p>
<div id="log-version-of-the-marginal" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> log version of the marginal:<a href="single-tree-model.html#log-version-of-the-marginal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This equation in log-scale gives us:</p>
<p><span class="math display">\[\begin{eqnarray*}
\log(\pi(\boldsymbol{y} | k_1, k_2, \mu, \alpha, \beta)) &amp;=&amp;
-\frac{N}{2} \log(2\pi)
-\frac{1}{2} \log(|\boldsymbol{\mathbf{W}}_{1}|) +
\log(\Gamma(N/2 + \alpha)) \\
&amp;-&amp; (N/2 + \alpha)\left[ \log \Big( \beta +
\frac{(\mathbf{y} - \mathbf{W}_{0})^T \mathbf{W}_{1}^{-1} (\mathbf{y} - \mathbf{W}_{0})}{2}\Big) \right]
\end{eqnarray*}\]</span></p>
<p>And the same, when written for <span class="math inline">\(j = 1,\dots, b\)</span> nodes
of a tree, would look like:</p>
<p><span class="math display">\[\begin{eqnarray*}
\sum_{j = 1}^{b} \log(\pi(\boldsymbol{y_{j}} | N_j, k_1, k_2, \mu, \alpha, \beta)) &amp;=&amp; \sum_{j = 1}^{b}
-\frac{N_j}{2} \log(2\pi) +
-\frac{1}{2} \log(|\boldsymbol{\mathbf{W}}_{1,j}|) +
\log(\Gamma(N_j/2 + \alpha)) \\
&amp;-&amp; (N_j/2 + \alpha)\left[ \log \Big(\beta +
\frac{(\mathbf{y}_j - \mathbf{W}_{0,j})^T \mathbf{W}_{1,j}^{-1} (\mathbf{y}_j - \mathbf{W}_{0,j})}{2} \Big) \right]
\end{eqnarray*}\]</span></p>
</div>
<div id="old-marginal-distributions" class="section level3 hasAnchor" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> (Old) Marginal Distributions<a href="single-tree-model.html#old-marginal-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This is only present here for the record.</p>
<p><span class="math display">\[y_{ij} \sim N(\mu_j, \tau^{-1})\]</span>
<span class="math display">\[\mu_j \sim N(\mu, k\tau^{-1})\]</span>
<span class="math display">\[\mu \sim N(\mu_\mu,\tau_\mu^{-1})\]</span>
<span class="math display">\[\tau \sim Ga(\alpha, \beta)\]</span></p>
<p>with <span class="math inline">\(N = \sum_{j = 1}^{m} n_j\)</span>. Define <span class="math inline">\(\mathbf{M}\)</span> to be an <span class="math inline">\(N\times m\)</span> binary matrix which allocates each observation to a group.</p>
<p>Writing things out in matrix format:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{y} =
\begin{bmatrix}
    y_{11}       \\
    y_{21}       \\
    \vdots        \\
    y_{n_m m}      
\end{bmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{M} =
\begin{bmatrix}
    0    &amp; 1   &amp; 0 \\
    1    &amp; 0   &amp; 0 \\
    1    &amp; 0   &amp; 0 \\
    \vdots &amp; \vdots &amp; \vdots        \\
    0    &amp; 0    &amp; 1
\end{bmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\lambda} =
\begin{bmatrix}
    \lambda_1       \\
    \vdots        \\
    \lambda_m
\end{bmatrix}
\end{equation}\]</span></p>
<p>then <span class="math inline">\(\boldsymbol{y} \sim MVN_{N}( \boldsymbol{M \lambda}, \tau^{-1} \boldsymbol{I})\)</span> and <span class="math inline">\(\boldsymbol{\lambda} \sim MVN_{m}( \mu \boldsymbol{1}, k \tau^{-1} \boldsymbol{I})\)</span>.</p>
<p><span class="math display">\[\begin{equation}
E[\boldsymbol{y} | \mu, \tau] = E_\lambda E_y[\boldsymbol{y} | \boldsymbol{\lambda}, \mu, \tau] =
\boldsymbol{M} E[\boldsymbol{\lambda}] = \mu \boldsymbol{M1} \\

Var[\boldsymbol{y} | \mu, \tau] = Var[\boldsymbol{M} \boldsymbol{\lambda}] +
\tau^{-1} \boldsymbol{I} = \boldsymbol{M} \boldsymbol{M}^{T}(k\tau^{-1}) + \tau^{-1} \boldsymbol{I}

\end{equation}\]</span></p>
<p>so
<span class="math display">\[\boldsymbol{y} | \mu, \tau, k, \tau_{\mu} \sim MVN_{N}(\mu \boldsymbol{M1} , \boldsymbol{M} \boldsymbol{M}^{T}(k\tau^{-1}) + \tau^{-1} \boldsymbol{I})\]</span></p>
<p><span class="math display">\[\boldsymbol{y} | \mu, \tau, k, \tau_{\mu} \sim MVN_{N}(\mu \boldsymbol{M1} , k\tau^{-1} + \tau^{-1} \boldsymbol{I}), \text{ since } \boldsymbol{M} \boldsymbol{M}^{T} = \boldsymbol{I}\]</span></p>
<p><span class="math display">\[\boldsymbol{y} | \mu, \tau, k, \tau_{\mu} \sim MVN_{N}(\mu \boldsymbol{M1} , \tau^{-1} (k + \boldsymbol{I}) )\]</span></p>
<p>We now use this as the starting point and integrate out <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>. The equation we end up with should be a function of <span class="math inline">\(M\)</span>, <span class="math inline">\(k\)</span>, <span class="math inline">\(\tau_\mu\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(\beta\)</span>.</p>
<p>To start, define: <span class="math inline">\(\Psi = (k + \boldsymbol{I})\)</span> so that <span class="math inline">\(y|\ldots \sim MVN(\mu \boldsymbol{M1}, \tau^{-1} \boldsymbol{\Psi})\)</span>. Then we obtain:</p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \tau_\mu, \mu_\mu, \alpha, \beta) &amp;=&amp; \int \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} \exp \left[ -\frac{\tau_\mu}{2} (\mu - \mu_\mu)^2 \right]\\
&amp;\times&amp;  \tau^{N/2} |\Psi|^{-1/2}  \exp \left[ -\frac{\tau}{2} \left\{  (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1} (\boldsymbol{y} - \mu \boldsymbol{M1}) \right\} \right] \partial\mu \partial\tau \\

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2}
\tau^{N/2} |\Psi|^{-1/2}\partial\tau  \\
&amp;\times&amp; \int \exp \left[ -\frac{1}{2} [\tau_\mu (\mu - \mu_\mu)^2 + \tau (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1}  (\boldsymbol{y} - \mu \boldsymbol{M1})] \right]  \partial\mu \\


\end{eqnarray*}\]</span></p>
<p>The inner expression can be rewritten as:</p>
<p><span class="math display">\[\begin{eqnarray*}
Q &amp;=&amp;
[\tau_\mu (\mu - \mu_\mu)^2 + \tau (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1}  (\boldsymbol{y} - \mu \boldsymbol{M1})] \\

&amp;=&amp; \mu^2(\tau_{\mu} + \tau (\boldsymbol{M1})^{T}\boldsymbol{\Psi}^{-1}     \boldsymbol{M1}) - 2\mu (\tau_{\mu} \mu_{\mu} +
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}) + \tau_{\mu} \mu_{\mu}^2 +
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}  \boldsymbol{y} \\

&amp;=&amp; \mu^2(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1}) - 2\mu (\tau_{\mu} \mu_{\mu} +
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}) + \tau_{\mu} \mu_{\mu}^2 +
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}  \boldsymbol{y} \\


&amp;=&amp; \tau_{\mu} \mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}  \boldsymbol{y}   +
(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})
\left(\mu - \frac{\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}}{\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1}}\right)^2 \\

&amp;+&amp; \frac{(\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1})^2}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})}\\

\end{eqnarray*}\]</span></p>
<p>that can be be plugged back into our equation as a
<span class="math inline">\(\text{Normal}(\frac{\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})}, (\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})^{-1})\)</span>:</p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \tau_\mu, \mu_\mu, \alpha, \beta)

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2}
\tau^{N/2} |\Psi|^{-1/2}\partial\tau  \\
&amp;\times&amp; \int \exp \left[ -\frac{1}{2} [\tau_\mu (\mu - \mu_\mu)^2 + \tau (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1} (\boldsymbol{y} - \mu \boldsymbol{M1})] \right]  \partial\mu \\


&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} \tau^{N/2} |\Psi|^{-1/2}\partial\tau  
\exp \left[ -\frac{1}{2}\{ \tau_{\mu} \mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right]  \\
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{
\frac{(\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1})^2}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})} \right \} \right]\\
&amp;\times&amp; \int \exp \left[ -\frac{1}{2} [
(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})
\left(\mu - \frac{\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}}{\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}\right)^2
\right] \\

&amp;\times&amp; \frac{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}} \thinspace
\thinspace \thinspace \partial\mu \\

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2}
\tau^{N/2} |\Psi|^{-1/2}
\exp \left[ -\frac{1}{2}\{ \tau_{\mu} \mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right] \\
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{
\frac{(\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi} ^{-1} \boldsymbol{M1})^2}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})} \right \} \right] \frac{1}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}} \thinspace
\thinspace \thinspace \partial\tau \\

\end{eqnarray*}\]</span></p>
<p><strong>Now, replacing <span class="math inline">\(\tau_{\mu} = k \tau\)</span>, we have:</strong></p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \mu_\mu, \alpha, \beta, \tau)

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times (k \tau)^{1/2}
\tau^{N/2} |\Psi|^{-1/2}
\exp \left[ -\frac{1}{2}\{ k \tau\mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right] \\
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{
\frac{(k \tau\mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{1})^2}{(k \tau + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})} \right \} \right] \frac{1}{(k \tau+ \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}} \thinspace
\thinspace \thinspace \partial\tau \\


&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \int \tau^{\alpha - 1} \tau^{1/2} \tau^{N/2}
\exp [ -\beta \tau] \times

\exp \left[ -\frac{\tau}{2}\{ k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right] \\
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{
\frac{(\tau (k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}))^2}{ (\tau (k + \boldsymbol{1}^{T}\boldsymbol{\Psi}\boldsymbol{1})} \right \} \right] \frac{1}{(\tau (k +   \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1}))^{1/2}} \thinspace
\thinspace \thinspace \partial\tau \\

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{(k + \boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}}
\int \tau^{\alpha - 1} \tau^{N/2} \\

&amp;\times&amp; \exp [ -\beta \tau] \times
\exp \left[ -\frac{\tau}{2}\{ k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} +
\boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} \} \right]
\thinspace \thinspace \partial\tau \\

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{(k + \boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}}
\int \tau^{N/2 + \alpha - 1} \\

&amp;\times&amp; \exp [ -\tau \{ \beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} ) \}]
\thinspace \thinspace \partial\tau \\

\end{eqnarray*}\]</span></p>
<p>where the main expression can be seen as a
<span class="math inline">\(\text{Gamma}(N/2 + \alpha, \beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} ))\)</span></p>
<p>and:</p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \mu_\mu, \alpha, \beta)

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{(k + \boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}}
\int \tau^{N/2 + \alpha - 1} \\
&amp;\times&amp; \exp [ -\tau \{ \beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} ) \}]
\thinspace \thinspace \\

&amp;\times&amp; \frac{
(\beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}))^{N/2 + \alpha}
}{
(\beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}))^{N/2 + \alpha}
} \partial\tau \\

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{k + (\boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}} \\
&amp;\times&amp;
(\beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} +
\boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}))^{-(N/2 + \alpha)}\\

\end{eqnarray*}\]</span></p>
<p>This equation in log-scale gives us:</p>
<p><span class="math display">\[\begin{eqnarray*}
\log(\pi(\boldsymbol{y} | k, \mu_\mu, \alpha, \beta)) &amp;=&amp;
-\frac{1}{2} \log(|\boldsymbol{\Psi}|) +
\frac{\log(k)}{2} - \log(k + ((\boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2})) \\
&amp;-&amp; (N/2 + \alpha)\left[ \log \beta + \log(1/2) + \log(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}) \right]

\end{eqnarray*}\]</span></p>
<p>And the same, when written for <span class="math inline">\(j = 1,\dots, b\)</span> nodes
of a tree, would look like:</p>
<p><span class="math display">\[\begin{eqnarray*}
\sum_{j = 1}^{b} \log(\pi(\boldsymbol{y_{j}} | k_{j}, \mu_{\mu_{j}}, \alpha, \beta)) &amp;=&amp;
\sum_{j = 1}^{b} -\frac{1}{2} \log(|\boldsymbol{\Psi_{j}}|) +
\frac{\log(k_{j})}{2} - \log(k_{j} + ((\boldsymbol{1}^{T}\boldsymbol{\Psi_{j}}^{-1}\boldsymbol{1})^{1/2})) \\
&amp;-&amp; (N_{j}/2 + \alpha) [ \log \beta + \log(1/2) + \log(k_{j} \mu_{\mu_{j}}^2 + \boldsymbol{y_{j}}^T \boldsymbol{\Psi_{j}}^{-1} \boldsymbol{y_{j}} \\ &amp;+&amp; \frac{(k_{j} \mu_{\mu_{j}}
\boldsymbol{y_{j}}^T \boldsymbol{\Psi_{j}}^{-1}\boldsymbol{M_{j} 1})^2}{k_{j} + \boldsymbol{1}^{T}\boldsymbol{\Psi_{j}}^{-1}\boldsymbol{1}})]

\end{eqnarray*}\]</span></p>

</div>
</div>
<div id="algorithm" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Algorithm<a href="single-tree-model.html#algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p><strong>Algorithm type</strong>: Metropolis within GIBBS for a hierachical Bayesian (single) tree</p>
<p><strong>Reason</strong>: We have closed posteriors for most parameters, but not for the tree structure</p>
<p><strong>Data</strong>: Target variable <span class="math inline">\(y\)</span>, groups <span class="math inline">\(j = 1,\dots,m\)</span>, set of
features X</p>
<p><strong>Result</strong>: Posterior distributions for all parameters</p>
<hr />
<p><strong>Initialisation</strong>;</p>
<p>Hyper-parameters values for <span class="math inline">\(\alpha, \beta, k_1, k_2\)</span>;</p>
<p>Number of groups <span class="math inline">\(m\)</span>;</p>
<p>Number of observations <span class="math inline">\(N =\sum_{j = 1}^{m} n_j\)</span>;</p>
<p>Number of iterations I;</p>
<ul>
<li><p>define <span class="math inline">\(\mu_{\mu} = 0\)</span>, <span class="math inline">\(\mu^{0}\)</span>, <span class="math inline">\(\tau^{0}\)</span>, and <span class="math inline">\(\mu_j^{0}, j = 1,\dots, m\)</span>
as the initial parameter values</p></li>
<li><p><strong>for</strong> i from 1 to I <strong>do</strong>:</p>
<ul>
<li><p>grow a new <span class="math inline">\(T^{\text{new}}\)</span> tree by either growing, pruning, changing
or swapping a root node</p></li>
<li><p>set <span class="math inline">\(l_{\text{new}}\)</span> = log full conditional for the
new (candidate) tree</p></li>
</ul></li>
</ul>
<center>
<span class="math inline">\(l_{\text{new}} = \sum_{l = 1}^{b_{\text{new}}} -\frac{1}{2} \log(|\boldsymbol{W}_{1,l}|) + \log(\Gamma(N_l/2 + \alpha))\)</span>
<span class="math inline">\(-(N_l/2 + \alpha)\left[ \log \beta + \log\Big(\frac{(\mathbf{y}_l - \mathbf{W}_{0,l})^T \mathbf{W}_{1,l}^{-1} (\mathbf{y}_l - \mathbf{W}_{0,l})}{2} \Big) \right]\)</span>
</center>
<ul>
<li>set <span class="math inline">\(l_{\text{old}}\)</span> = log full conditional for the
previous tree</li>
</ul>
<center>
<span class="math inline">\(l_{\text{old}} = \sum_{l = 1}^{b_{\text{old}}} -\frac{1}{2} \log(|\boldsymbol{W}_{1,l}|) + \log(\Gamma(N_l/2 + \alpha))\)</span>
<span class="math inline">\(-(N_l/2 + \alpha)\left[ \log \beta + \log\Big(\frac{(\mathbf{y}_l - \mathbf{W}_{0,l})^T \mathbf{W}_{1,l}^{-1} (\mathbf{y}_l - \mathbf{W}_{0,l})}{2} \Big) \right]\)</span>
</center>
<ul>
<li><p>set <span class="math inline">\(a = \exp(l_{\text{new}} - l_{\text{old}})\)</span></p></li>
<li><p>generate <span class="math inline">\(u \sim U[0, 1]\)</span></p></li>
<li><p><strong>if</strong> <span class="math inline">\(u &lt; a\)</span> <strong>then</strong>:</p>
<ul>
<li>set <span class="math inline">\(T = T^{\text{new}}\)</span></li>
</ul></li>
<li><p><strong>end</strong></p></li>
<li><p>sample <span class="math inline">\(\mu\)</span> from the posterior <span class="math inline">\(N(\frac{(\tau/k_1) \bar \mu m}{\tau(\frac{1}{k_2} + \frac{m}{k_1})}, (\tau(\frac{1}{k_2} + \frac{m}{k_1}) )^{-1})\)</span> (because of <span class="math inline">\(\bar \mu\)</span>)</p></li>
<li><p><strong>for</strong> j in 1:m <strong>do</strong>:</p>
<ul>
<li>sample <span class="math inline">\(\mu_j\)</span> from the posterior <span class="math inline">\(N(\frac{\mu/k_1 + \bar y_j n_j}{n_j + 1/k_1}, ((n_j + \frac{1}{k_1})\tau)^{-1})\)</span></li>
</ul></li>
<li><p><strong>end</strong></p></li>
<li><p>sample <span class="math inline">\(\tau\)</span> from the posterior <span class="math inline">\(\text{Gamma}\Big(n/2 + \alpha, \beta + \frac{(\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)}{2}\Big)\)</span></p></li>
<li><p><strong>end</strong></p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="initial-results.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book2.pdf", "book2.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
